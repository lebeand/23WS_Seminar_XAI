

@article{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{vstrumbelj2014explaining,
  title={Explaining prediction models and individual predictions with feature contributions},
  author={{\v{S}}trumbelj, Erik and Kononenko, Igor},
  journal={Knowledge and information systems},
  volume={41},
  pages={647--665},
  year={2014},
  publisher={Springer}
}

@article{shapley1953value,
  title={A value for n-person games},
  author={Shapley, Lloyd S and others},
  year={1953},
  publisher={Princeton University Press Princeton}
}

@article{NALLAKARUPPAN2024111307,
title = {An Explainable AI framework for credit evaluation and analysis},
journal = {Applied Soft Computing},
volume = {153},
pages = {111307},
year = {2024},
author = {M.K. Nallakaruppan and Balamurugan Balusamy and M. Lawanya Shri and V. Malathi and Siddhartha Bhattacharyya}
}
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.111307},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624000814},

@inproceedings{slack2020fooling,
  title={Fooling lime and shap: Adversarial attacks on post hoc explanation methods},
  author={Slack, Dylan and Hilgard, Sophie and Jia, Emily and Singh, Sameer and Lakkaraju, Himabindu},
  booktitle={Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
  pages={180--186},
  year={2020}
}

@misc{linear_tree,
  title = {The Best of Both Worlds: Linear Model Trees},
  url = {https://medium.com/convoy-tech/the-best-of-both-worlds-linear-model-trees-7c9ce139767d},
  note = {Accessed on: February 7, 2024}
}

@article{barnett2021case,
  title={A case-based interpretable deep learning model for classification of mass lesions in digital mammography},
  author={Barnett, Alina Jade and Schwartz, Fides Regina and Tao, Chaofan and Chen, Chaofan and Ren, Yinhao and Lo, Joseph Y and Rudin, Cynthia},
  journal={Nature Machine Intelligence},
  volume={3},
  number={12},
  pages={1061--1070},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@article{MARKUS2021103655,
title = {The role of explainability in creating trustworthy artificial intelligence for health care: A comprehensive survey of the terminology, design choices, and evaluation strategies},
journal = {Journal of Biomedical Informatics},
volume = {113},
pages = {103655},
year = {2021},
author = {Aniek F. Markus and Jan A. Kors and Peter R. Rijnbeek}
}
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2020.103655},
url = {https://www.sciencedirect.com/science/article/pii/S1532046420302835},


@article{Ghorbani_Abid_Zou_2019, 
title={Interpretation of Neural Networks Is Fragile}, 
volume={33},
number={01}, 
journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
author={Ghorbani, Amirata and Abid, Abubakar and Zou, James}, 
year={2019}, 
pages={3681-3688} 
}

@misc{simonyan2014deep,
      title={Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps}, 
      author={Karen Simonyan and Andrea Vedaldi and Andrew Zisserman},
      year={2014},
      eprint={1312.6034},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{breiman2001random,
  title={Random forests},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={45},
  pages={5--32},
  year={2001},
  publisher={Springer}
}

@article{fisher2019all,
  title={All Models are Wrong, but Many are Useful: Learning a Variable's Importance by Studying an Entire Class of Prediction Models Simultaneously.},
  author={Fisher, Aaron and Rudin, Cynthia and Dominici, Francesca},
  journal={J. Mach. Learn. Res.},
  volume={20},
  number={177},
  pages={1--81},
  year={2019}
}

@article{rudin2019stop,
  title={Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
  author={Rudin, Cynthia},
  journal={Nature machine intelligence},
  volume={1},
  number={5},
  pages={206--215},
  year={2019},
}

@book{hastie2009elements,
  title={The elements of statistical learning: data mining, inference, and prediction},
  author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome H and Friedman, Jerome H},
  volume={2},
  year={2009},
  publisher={Springer}
}

@misc{diabetes_dataset,
  title = {Diabetes Dataset},
  url = {https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn-datasets-load-diabetes},
  note = {Accessed on: February 7, 2024}
}

@misc{freiesleben2022scientific,
      title={Scientific Inference With Interpretable Machine Learning: Analyzing Models to Learn About Real-World Phenomena}, 
      author={Timo Freiesleben and Gunnar KÃ¶nig and Christoph Molnar and Alvaro Tejero-Cantero},
      year={2022},
      eprint={2206.05487},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{InterpretableToWhom,
  author       = {Richard Tomsett and
                  Dave Braines and
                  Dan Harborne and
                  Alun D. Preece and
                  Supriyo Chakraborty},
  title        = {Interpretable to Whom? {A} Role-based Model for Analyzing Interpretable Machine Learning Systems},
  journal      = {CoRR},
  year         = {2018},
}

@article{hassija2024interpreting,
  title={Interpreting black-box models: a review on explainable artificial intelligence},
  author={Hassija, Vikas and Chamola, Vinay and Mahapatra, Atmesh and Singal, Abhinandan and Goel, Divyansh and Huang, Kaizhu and Scardapane, Simone and Spinelli, Indro and Mahmud, Mufti and Hussain, Amir},
  journal={Cognitive Computation},
  volume={16},
  number={1},
  pages={45--74},
  year={2024},
  publisher={Springer}
}

@book{molnar2022,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  year       = {2022},
  subtitle   = {A Guide for Making Black Box Models Explainable},
  edition    = {2},
  url        = {https://christophm.github.io/interpretable-ml-book}
}

@inproceedings{NEURIPS2019_adf7ee2d,
 author = {Chen, Chaofan and Li, Oscar and Tao, Daniel and Barnett, Alina and Rudin, Cynthia and Su, Jonathan K},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 publisher = {Curran Associates, Inc.},
 title = {This Looks Like That: Deep Learning for Interpretable Image Recognition},
 volume = {32},
 year = {2019}
}
url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/adf7ee2dcf142b0e11888e72b43fcb75-Paper.pdf},
